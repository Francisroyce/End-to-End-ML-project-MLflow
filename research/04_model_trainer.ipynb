{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ceb15c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bc55aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcab7369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\user\\\\Desktop\\\\End-to-End-ML-project-MLflow'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4265f858",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\user\\Desktop\\End-to-End-ML-project-MLflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6074eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    trained_data_path: Path\n",
    "    test_data_path: Path\n",
    "    model_name: str\n",
    "    params: dict          # ✅ hyperparameter grid\n",
    "    target_column: str\n",
    "    evaluation_metric: str = \"r2\"   # ✅ default metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e81c0830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_project.constants import *\n",
    "from my_project.utils.common import read_yaml, create_directories\n",
    "from pathlib import Path\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath: Path = CONFIG_FILE_PATH,\n",
    "        params_filepath: Path = PARAMS_FILE_PATH,\n",
    "        schema_filepath: Path = SCHEMA_FILE_PATH,\n",
    "    ):\n",
    "        # Load configs\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        # Ensure artifacts root exists\n",
    "        create_directories([Path(self.config.artifacts_root)])\n",
    "\n",
    "    def get_model_trainer_configs(self) -> dict[str, ModelTrainerConfig]:\n",
    "        \"\"\"\n",
    "        Returns a dictionary of model_name -> ModelTrainerConfig\n",
    "        \"\"\"\n",
    "        config = self.config.model_trainer\n",
    "        schema = self.schema.target_column\n",
    "        eval_metric = self.params.model_evaluation.evaluation_metric\n",
    "\n",
    "        configs = {}\n",
    "        create_directories([Path(config.root_dir)])\n",
    "\n",
    "        for model_name, model_params in self.params.models.items():\n",
    "            model_trainer_config = ModelTrainerConfig(\n",
    "                root_dir=Path(config.root_dir),\n",
    "                trained_data_path=Path(config.trained_data_path),\n",
    "                test_data_path=Path(config.test_data_path),\n",
    "                model_name=model_name,\n",
    "                params=model_params,\n",
    "                target_column=schema,\n",
    "                evaluation_metric=eval_metric,\n",
    "            )\n",
    "            configs[model_name] = model_trainer_config\n",
    "\n",
    "        return configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7e5b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "from my_project import logging\n",
    "from functools import reduce\n",
    "from operator import mul\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "        # Candidate models\n",
    "        self.models = {\n",
    "            \"elasticnet\": ElasticNet(),\n",
    "            \"randomforest\": RandomForestRegressor(),\n",
    "            \"xgbregressor\": XGBRegressor(objective=\"reg:squarederror\"),\n",
    "        }\n",
    "\n",
    "        # Available metrics\n",
    "        self.metrics = {\n",
    "            \"r2\": r2_score,\n",
    "            \"mse\": mean_squared_error,\n",
    "            \"mae\": mean_absolute_error,\n",
    "        }\n",
    "\n",
    "    def _count_total_param_combinations(self, params):\n",
    "        sizes = [len(v) for v in params.values()]\n",
    "        return reduce(mul, sizes, 1)\n",
    "\n",
    "    def tune_model(self, model, params, x_train, y_train, scoring, n_iter=20):\n",
    "        \"\"\"\n",
    "        Use RandomizedSearchCV for faster tuning.\n",
    "        n_iter = number of random combinations (dynamic)\n",
    "        \"\"\"\n",
    "        total_combinations = self._count_total_param_combinations(params)\n",
    "        n_iter = min(n_iter, total_combinations)  # avoid warning\n",
    "\n",
    "        search = RandomizedSearchCV(\n",
    "            model,\n",
    "            params,\n",
    "            n_iter=n_iter,\n",
    "            cv=3,\n",
    "            scoring=scoring,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            error_score=\"raise\"\n",
    "        )\n",
    "        search.fit(x_train, y_train)\n",
    "        return search.best_estimator_, search.best_params_\n",
    "\n",
    "    def initiate_model_trainer(self):\n",
    "        logging.info(\"Loading training and test data\")\n",
    "        train_df = pd.read_csv(self.config.trained_data_path)\n",
    "        test_df = pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "        target_column = self.config.target_column\n",
    "        x_train, y_train = train_df.drop(columns=[target_column]), train_df[target_column]\n",
    "        x_test, y_test = test_df.drop(columns=[target_column]), test_df[target_column]\n",
    "\n",
    "        logging.info(\"Training and tuning models\")\n",
    "        params = self.config.params\n",
    "        model = self.models[self.config.model_name]\n",
    "\n",
    "        # Tune model\n",
    "        tuned_model, tuned_params = self.tune_model(\n",
    "            model, params, x_train, y_train,\n",
    "            scoring=self.config.evaluation_metric,\n",
    "            n_iter=30\n",
    "        )\n",
    "\n",
    "        # Make predictions and evaluate\n",
    "        preds = tuned_model.predict(x_test)\n",
    "        metric_fn = self.metrics.get(self.config.evaluation_metric, r2_score)\n",
    "        score = metric_fn(y_test, preds)\n",
    "\n",
    "        logging.info(f\"{self.config.model_name} -> Score: {score:.4f}, Best Params: {tuned_params}\")\n",
    "\n",
    "        # Save model\n",
    "        model_path = os.path.join(self.config.root_dir, f\"{self.config.model_name}.pkl\")\n",
    "        joblib.dump(tuned_model, model_path)\n",
    "\n",
    "        # Save best params\n",
    "        params_file = os.path.join(self.config.root_dir, f\"{self.config.model_name}_best_params.json\")\n",
    "        with open(params_file, \"w\") as f:\n",
    "            json.dump({\"model_name\": self.config.model_name, **tuned_params}, f, indent=4)\n",
    "\n",
    "        logging.info(f\"Model saved at: {model_path}\")\n",
    "        logging.info(f\"Params saved at: {params_file}\")\n",
    "\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb0884f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-05 11:54:33,944 - my_project - INFO - YAML file 'config\\config.yaml' read successfully.\n",
      "2025-09-05 11:54:33,963 - my_project - INFO - YAML file 'params.yaml' read successfully.\n",
      "2025-09-05 11:54:33,976 - my_project - INFO - YAML file 'schema.yaml' read successfully.\n",
      "2025-09-05 11:54:33,982 - my_project - INFO - Directory created: 'artifacts'\n",
      "2025-09-05 11:54:33,982 - my_project - INFO - Directory created: 'artifacts\\model_trainer'\n",
      "2025-09-05 11:54:33,995 - root - INFO - Loading training and test data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-05 11:54:34,090 - root - INFO - Training and tuning models\n",
      "2025-09-05 11:54:47,514 - root - INFO - elasticnet -> Score: 0.4139, Best Params: {'random_state': 42, 'l1_ratio': 0.1, 'alpha': 0.001}\n",
      "2025-09-05 11:54:47,534 - root - INFO - Model saved at: artifacts\\model_trainer\\elasticnet.pkl\n",
      "2025-09-05 11:54:47,541 - root - INFO - Params saved at: artifacts\\model_trainer\\elasticnet_best_params.json\n",
      "2025-09-05 11:54:47,545 - root - INFO - Loading training and test data\n",
      "2025-09-05 11:54:47,582 - root - INFO - Training and tuning models\n",
      "2025-09-05 11:55:23,821 - root - INFO - randomforest -> Score: 0.5315, Best Params: {'random_state': 42, 'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 20}\n",
      "2025-09-05 11:55:24,327 - root - INFO - Model saved at: artifacts\\model_trainer\\randomforest.pkl\n",
      "2025-09-05 11:55:24,331 - root - INFO - Params saved at: artifacts\\model_trainer\\randomforest_best_params.json\n",
      "2025-09-05 11:55:24,331 - root - INFO - Loading training and test data\n",
      "2025-09-05 11:55:24,362 - root - INFO - Training and tuning models\n",
      "2025-09-05 11:55:33,319 - root - INFO - xgbregressor -> Score: 0.5078, Best Params: {'subsample': 0.8, 'reg_lambda': 2.0, 'reg_alpha': 0, 'random_state': 42, 'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05, 'gamma': 0, 'colsample_bytree': 0.8}\n",
      "2025-09-05 11:55:33,363 - root - INFO - Model saved at: artifacts\\model_trainer\\xgbregressor.pkl\n",
      "2025-09-05 11:55:33,367 - root - INFO - Params saved at: artifacts\\model_trainer\\xgbregressor_best_params.json\n",
      "\n",
      "📊 Model Results:\n",
      "elasticnet      -> 0.4139\n",
      "randomforest    -> 0.5315\n",
      "xgbregressor    -> 0.5078\n",
      "\n",
      "✅ Best model: randomforest with score 0.5315\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_configs = config.get_model_trainer_configs()\n",
    "\n",
    "    results = []\n",
    "    for model_name, trainer_config in model_trainer_configs.items():\n",
    "        try:\n",
    "            model_trainer = ModelTrainer(config=trainer_config)\n",
    "            score = model_trainer.initiate_model_trainer()\n",
    "            results.append((model_name, score))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipping {model_name} due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\n📊 Model Results:\")\n",
    "    for name, score in results:\n",
    "        print(f\"{name:15} -> {score:.4f}\")\n",
    "\n",
    "    # Pick best\n",
    "    best_model, best_score = max(results, key=lambda x: x[1])\n",
    "    print(f\"\\n✅ Best model: {best_model} with score {best_score:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d28196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
